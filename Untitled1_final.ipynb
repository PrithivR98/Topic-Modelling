{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4699a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\prith\\anaconda3\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\prith\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\prith\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\prith\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\prith\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\prith\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\prith\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prith\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prith\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\prith\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\prith\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy scikit-learn pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b69829e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prith\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\prith\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\prith\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\prith\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "C:\\Users\\prith\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Running Time: 0.5970 seconds\n",
      "NMF Running Time: 1.8824 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "import time\n",
    "\n",
    "# Fetch sample data - 20 newsgroups dataset\n",
    "data = fetch_20newsgroups(subset='all', shuffle=True, random_state=42)\n",
    "documents = data.data\n",
    "\n",
    "# Preprocess text data using TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# LSA (Latent Semantic Analysis)\n",
    "start_time = time.time()\n",
    "lsa = TruncatedSVD(n_components=10, random_state=42)\n",
    "lsa_topics = lsa.fit_transform(tfidf)\n",
    "lsa_time = time.time() - start_time\n",
    "\n",
    "# NMF (Non-Negative Matrix Factorization)\n",
    "start_time = time.time()\n",
    "nmf = NMF(n_components=10, random_state=42)\n",
    "nmf_topics = nmf.fit_transform(tfidf)\n",
    "nmf_time = time.time() - start_time\n",
    "\n",
    "print(f\"LSA Running Time: {lsa_time:.4f} seconds\")\n",
    "print(f\"NMF Running Time: {nmf_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfd9a106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF Running Time: 1.9180 seconds\n",
      "LSA Running Time: 0.5215 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "import time\n",
    "\n",
    "# Fetch sample data - 20 newsgroups dataset\n",
    "data = fetch_20newsgroups(subset='all', shuffle=True, random_state=42)\n",
    "documents = data.data\n",
    "\n",
    "# Preprocess text data using TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# NMF (Non-Negative Matrix Factorization)\n",
    "start_time = time.time()\n",
    "nmf = NMF(n_components=10, random_state=42)\n",
    "nmf_topics = nmf.fit_transform(tfidf)\n",
    "nmf_time = time.time() - start_time\n",
    "\n",
    "# LSA (Latent Semantic Analysis)\n",
    "start_time = time.time()\n",
    "lsa = TruncatedSVD(n_components=10, random_state=42)\n",
    "lsa_topics = lsa.fit_transform(tfidf)\n",
    "lsa_time = time.time() - start_time\n",
    "\n",
    "print(f\"NMF Running Time: {nmf_time:.4f} seconds\")\n",
    "print(f\"LSA Running Time: {lsa_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d3092a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Topics:\n",
      "Topic #0: don just like know people think does use time good\n",
      "Topic #1: windows thanks drive card dos file pc scsi software program\n",
      "Topic #2: god windows jesus does bible thanks christ dos christian faith\n",
      "Topic #3: drive scsi god ide hard card controller drives disk game\n",
      "Topic #4: drive key scsi chip government encryption clipper keys law ide\n",
      "\n",
      "NMF Topics:\n",
      "Topic #0: don just people think like good know time did right\n",
      "Topic #1: windows thanks file dos program does know files mail use\n",
      "Topic #2: god jesus bible believe christ christian faith christians does sin\n",
      "Topic #3: drive scsi card ide disk hard controller drives bus floppy\n",
      "Topic #4: key chip encryption clipper government keys escrow use law algorithm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "import numpy as np\n",
    "\n",
    "# Load the 20 newsgroups dataset\n",
    "data = fetch_20newsgroups(subset='all', shuffle=True, remove=('headers', 'footers', 'quotes'))\n",
    "documents = data.data\n",
    "\n",
    "# Vectorize the text data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Perform LSA (Truncated SVD)\n",
    "lsa = TruncatedSVD(n_components=5, random_state=42)\n",
    "lsa_topics = lsa.fit_transform(tfidf)\n",
    "\n",
    "# Perform NMF\n",
    "nmf = NMF(n_components=5, random_state=42)\n",
    "nmf_topics = nmf.fit_transform(tfidf)\n",
    "\n",
    "# Print top words for each topic for both LSA and NMF\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = f\"Topic #{topic_idx}: \"\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "\n",
    "n_top_words = 10\n",
    "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"LSA Topics:\")\n",
    "print_top_words(lsa, feature_names, n_top_words)\n",
    "\n",
    "print(\"\\nNMF Topics:\")\n",
    "print_top_words(nmf, feature_names, n_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a92ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Topics:\n",
      "Topic #0: don just like know people think does use time good\n",
      "Topic #1: windows thanks drive card dos file pc software scsi program\n",
      "Topic #2: god windows jesus does bible thanks christ christian dos faith\n",
      "Topic #3: drive scsi god ide card controller hard drives game disk\n",
      "Topic #4: drive key scsi government chip encryption clipper people keys ide\n",
      "Topic #5: windows dos file think problem drive os window run disk\n",
      "Topic #6: know thanks don does just like drive car people advance\n",
      "Topic #7: key game chip does god clipper encryption keys know team\n",
      "Topic #8: geb edu dsl cadre n3jxp pitt chastity skepticism intellect shameful\n",
      "Topic #9: car just bike 00 good ve new god engine like\n",
      "\n",
      "NMF Topics:\n",
      "Topic #0: don just like think know good ve time really want\n",
      "Topic #1: windows dos file program files window use using run running\n",
      "Topic #2: god jesus bible believe christ faith christian christians sin church\n",
      "Topic #3: drive scsi ide disk card controller hard drives bus floppy\n",
      "Topic #4: key chip encryption clipper keys government escrow use algorithm phone\n",
      "Topic #5: thanks does know mail advance hi info looking information help\n",
      "Topic #6: 00 new 10 sale car price 50 20 shipping offer\n",
      "Topic #7: game games team year hockey baseball season players play espn\n",
      "Topic #8: edu geb dsl cadre n3jxp chastity pitt skepticism intellect shameful\n",
      "Topic #9: people government israel armenian jews armenians gun state did children\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "import numpy as np\n",
    "\n",
    "# Load the 20 newsgroups dataset\n",
    "data = fetch_20newsgroups(subset='all', shuffle=True, remove=('headers', 'footers', 'quotes'))\n",
    "documents = data.data\n",
    "\n",
    "# Vectorize the text data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Perform LSA (Truncated SVD)\n",
    "lsa = TruncatedSVD(n_components=10, random_state=42)\n",
    "lsa_topics = lsa.fit_transform(tfidf)\n",
    "\n",
    "# Perform NMF\n",
    "nmf = NMF(n_components=10, random_state=42)\n",
    "nmf_topics = nmf.fit_transform(tfidf)\n",
    "\n",
    "# Print top words for each topic for both LSA and NMF\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = f\"Topic #{topic_idx}: \"\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "\n",
    "n_top_words = 10\n",
    "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"LSA Topics:\")\n",
    "print_top_words(lsa, feature_names, n_top_words)\n",
    "\n",
    "print(\"\\nNMF Topics:\")\n",
    "print_top_words(nmf, feature_names, n_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d372853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
